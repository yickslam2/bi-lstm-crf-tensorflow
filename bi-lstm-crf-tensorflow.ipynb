{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from random import random\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used.\n",
    "MODEL_PATH = 'model/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequence classification instance.\n",
    "def get_sequence(sequence_length):\n",
    "    # Create a sequence of random numbers in [0,1].\n",
    "    X = np.array([random() for _ in range(sequence_length)])\n",
    "    # Calculate cut-off value to change class values.\n",
    "    limit = sequence_length / 4.0\n",
    "    # Determine the class outcome for each item in cumulative sequence.\n",
    "    y = np.array([0 if x < limit else 1 for x in np.cumsum(X)])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Create n examples with random sequence lengths between 5 and 15.\n",
    "def get_examples(n):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    sequence_length_list = []\n",
    "    for _ in range(n):\n",
    "        sequence_length = rand.randrange(start=5, stop=15)\n",
    "        X, y = get_sequence(sequence_length)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sequence_length_list.append(sequence_length)\n",
    "    \n",
    "    return X_list, y_list, sequence_length_list\n",
    "\n",
    "# Tensorflow requires that all sentences (and all labels) inside the same batch have the same length,\n",
    "# so we have to pad the data (and labels) inside the batches (with 0's, for example).\n",
    "def pad(sentence, max_length):\n",
    "    pad_len = max_length - len(sentence)\n",
    "    padding = np.zeros(pad_len)\n",
    "    return np.concatenate((sentence, padding))\n",
    "    \n",
    "# Create input batches.\n",
    "def batch(data, labels, sequence_lengths, batch_size, input_size):\n",
    "    n_batch = int(math.ceil(len(data) / batch_size))\n",
    "    index = 0\n",
    "    for _ in range(n_batch):\n",
    "        batch_sequence_lengths = np.array(sequence_lengths[index: index + batch_size])\n",
    "        batch_length = np.array(max(batch_sequence_lengths)) # max length in batch\n",
    "        batch_data = np.array([pad(x, batch_length) for x in data[index: index + batch_size]]) # pad data\n",
    "        batch_labels = np.array([pad(x, batch_length) for x in labels[index: index + batch_size]]) # pad labels\n",
    "        index += batch_size\n",
    "        \n",
    "        # Reshape input data to be suitable for LSTMs.\n",
    "        batch_data = batch_data.reshape(-1, batch_length, input_size)\n",
    "        \n",
    "        yield batch_data, batch_labels, batch_length, batch_sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.72161455, 0.10044801, 0.62441248, 0.11644938, 0.73457546,\n",
       "         0.09107931, 0.76864257, 0.90909978]),\n",
       "  array([0.0435622 , 0.48185876, 0.90462488, 0.04559231, 0.05141588,\n",
       "         0.36246348, 0.84370197, 0.24516594, 0.3384236 , 0.13938621,\n",
       "         0.48540136, 0.00241523, 0.85818727]),\n",
       "  array([0.32957779, 0.75325987, 0.93908048, 0.24727915, 0.84712438,\n",
       "         0.30937242]),\n",
       "  array([0.60445865, 0.27168677, 0.66577422, 0.79512854, 0.23837496,\n",
       "         0.91490164, 0.88455222, 0.35216039, 0.8464526 , 0.19251423,\n",
       "         0.44061645, 0.49701923, 0.22242808]),\n",
       "  array([0.44908534, 0.01323662, 0.07992941, 0.66066615, 0.77780866,\n",
       "         0.70375184, 0.39316483, 0.0552906 , 0.4021665 , 0.7545499 ,\n",
       "         0.69365453]),\n",
       "  array([0.71400668, 0.96327124, 0.01267099, 0.12206486, 0.55191446,\n",
       "         0.4275188 , 0.2360379 , 0.64165656]),\n",
       "  array([0.28635105, 0.03794529, 0.24771914, 0.04708562, 0.49417498,\n",
       "         0.3699137 , 0.82468776, 0.58877614, 0.00781169, 0.42421517,\n",
       "         0.62214311, 0.35753273]),\n",
       "  array([0.97208411, 0.76313053, 0.45280717, 0.49032624, 0.38587908,\n",
       "         0.92663223, 0.06244015, 0.26910919, 0.24840363, 0.28797387,\n",
       "         0.539193  ]),\n",
       "  array([0.57546341, 0.94773003, 0.10660655, 0.53939854, 0.01311898,\n",
       "         0.19929473, 0.96058432]),\n",
       "  array([0.05938701, 0.33400771, 0.41319666, 0.93872844, 0.78449879,\n",
       "         0.19780908, 0.60655839, 0.70305625, 0.42356837, 0.15370667,\n",
       "         0.66752986, 0.2030313 , 0.50243358, 0.38681376]),\n",
       "  array([0.17643063, 0.37552291, 0.67060724, 0.22646115, 0.05199004,\n",
       "         0.27171712, 0.85994625, 0.62914787]),\n",
       "  array([0.29686259, 0.23791049, 0.46296166, 0.03526894, 0.49286911,\n",
       "         0.94251728]),\n",
       "  array([0.59869555, 0.89189182, 0.04246757, 0.34468531, 0.89337018,\n",
       "         0.73042187, 0.11380902, 0.72263704, 0.10556842, 0.02393814,\n",
       "         0.12101358, 0.86740407]),\n",
       "  array([0.7297225 , 0.89311119, 0.99977247, 0.64325777, 0.92243796,\n",
       "         0.7183108 , 0.90561519, 0.06232362]),\n",
       "  array([0.37835944, 0.12280552, 0.37745019, 0.70534669, 0.83373246,\n",
       "         0.75347836]),\n",
       "  array([0.91575608, 0.86984731, 0.37235999, 0.24594217, 0.864792  ,\n",
       "         0.42589678, 0.11301339, 0.71799345, 0.95997192, 0.3497909 ,\n",
       "         0.90452743]),\n",
       "  array([0.39565304, 0.85876673, 0.42076222, 0.97003341, 0.23743205,\n",
       "         0.13117502, 0.12082969, 0.4656624 , 0.95090127, 0.91225972,\n",
       "         0.04022903, 0.82244452, 0.38341221]),\n",
       "  array([0.97571053, 0.87449075, 0.99567089, 0.89483897, 0.53761065,\n",
       "         0.13940878, 0.59845703, 0.30226176, 0.37560184, 0.21885442,\n",
       "         0.71353526]),\n",
       "  array([0.29322709, 0.46611975, 0.51302331, 0.71377171, 0.7639181 ,\n",
       "         0.83755386]),\n",
       "  array([0.68611858, 0.56185688, 0.0868843 , 0.46178694, 0.53468888,\n",
       "         0.17363381, 0.55165077, 0.3941995 ]),\n",
       "  array([0.70903943, 0.54677178, 0.82819226, 0.74642429, 0.41739284,\n",
       "         0.77979643, 0.51987097, 0.8225808 , 0.77271686, 0.80612345,\n",
       "         0.73318486, 0.53412943]),\n",
       "  array([0.87886578, 0.75044856, 0.92714216, 0.43466664, 0.90685083,\n",
       "         0.62782527]),\n",
       "  array([0.3736378 , 0.00934744, 0.50307459, 0.39407748, 0.00761108,\n",
       "         0.86505475, 0.82136997, 0.83291169, 0.29863557, 0.22733419,\n",
       "         0.29789017]),\n",
       "  array([0.37481505, 0.17779746, 0.68697832, 0.34174622, 0.88842541,\n",
       "         0.98169514, 0.60852017]),\n",
       "  array([0.64106984, 0.68616218, 0.42206032, 0.12288976, 0.91820816,\n",
       "         0.00538962, 0.42825121, 0.99942443]),\n",
       "  array([0.66960396, 0.3979765 , 0.82166737, 0.34432967, 0.20500627,\n",
       "         0.89213993, 0.22898734, 0.41720977, 0.24725133, 0.43909061,\n",
       "         0.2609849 , 0.45601469, 0.68564553, 0.95664409]),\n",
       "  array([0.19456486, 0.40748394, 0.74001887, 0.87631514, 0.51397028,\n",
       "         0.23319027, 0.49108054, 0.37669762, 0.63520255, 0.34344416,\n",
       "         0.18892729, 0.44145163, 0.99034345, 0.25635746]),\n",
       "  array([0.5461099 , 0.8209935 , 0.41261652, 0.21267188, 0.75843384,\n",
       "         0.69952748, 0.02012146, 0.30316055, 0.42690754, 0.38263979,\n",
       "         0.55974213]),\n",
       "  array([0.4245785 , 0.3415791 , 0.48711627, 0.63075647, 0.94045503,\n",
       "         0.78698938, 0.74835983, 0.65086709, 0.59067484, 0.04715796,\n",
       "         0.82088317, 0.97232278, 0.55895197]),\n",
       "  array([0.19954601, 0.78156178, 0.52218934, 0.01651135, 0.49901451,\n",
       "         0.80681501, 0.11424945, 0.24354041, 0.50156432, 0.39357407,\n",
       "         0.60878591]),\n",
       "  array([0.69283678, 0.79455253, 0.34095243, 0.52793268, 0.17347929,\n",
       "         0.62213973, 0.7841319 , 0.58857788, 0.04157467, 0.3888645 ]),\n",
       "  array([0.42299233, 0.8867385 , 0.97627366, 0.48700112, 0.96507402]),\n",
       "  array([0.40410772, 0.2861313 , 0.54389943, 0.58248842, 0.42139048,\n",
       "         0.00380107, 0.3061578 , 0.35250194, 0.37966548]),\n",
       "  array([0.82400579, 0.84389061, 0.50967177, 0.72784005, 0.63135703,\n",
       "         0.39221298, 0.1576105 , 0.22104625, 0.19978082]),\n",
       "  array([0.25325045, 0.8343414 , 0.98139744, 0.67820232, 0.88513866,\n",
       "         0.64844159, 0.08979869, 0.40746261]),\n",
       "  array([0.00213286, 0.01600319, 0.4483289 , 0.92168953, 0.51906065,\n",
       "         0.65180133, 0.79865726, 0.66068772, 0.32058345, 0.06838845,\n",
       "         0.68827111, 0.32776624, 0.46328777]),\n",
       "  array([0.2687427 , 0.32848688, 0.79777745, 0.76445908, 0.2264346 ,\n",
       "         0.40298822, 0.78047283]),\n",
       "  array([0.17675757, 0.71653939, 0.28595891, 0.43861097, 0.42825776,\n",
       "         0.96470433, 0.5298042 , 0.95817336, 0.37429383, 0.80279383,\n",
       "         0.47369823, 0.77967737]),\n",
       "  array([0.2683302 , 0.83574521, 0.12863696, 0.90445359, 0.63322459,\n",
       "         0.95838054, 0.52041069, 0.96487962, 0.72984378, 0.50898213]),\n",
       "  array([0.40879016, 0.15522841, 0.0933076 , 0.32040791, 0.1501879 ,\n",
       "         0.82965233, 0.29179479, 0.44157855]),\n",
       "  array([0.72187339, 0.27951497, 0.8676432 , 0.65920526, 0.71690365,\n",
       "         0.49044954, 0.35845874, 0.80877704, 0.66584698, 0.35032012,\n",
       "         0.56871596, 0.34662117, 0.64522163, 0.01114354]),\n",
       "  array([0.30354445, 0.91230219, 0.09374624, 0.77677631, 0.92203751,\n",
       "         0.98426635]),\n",
       "  array([0.11797339, 0.45870825, 0.96130909, 0.96906134, 0.07270558,\n",
       "         0.51754792, 0.69063987, 0.99981646, 0.79166459, 0.08060082]),\n",
       "  array([0.45129765, 0.22347056, 0.34458552, 0.24408435, 0.82965306,\n",
       "         0.76284484, 0.10482348, 0.07638908, 0.41128519, 0.10459289,\n",
       "         0.75450183, 0.69425813, 0.80516157, 0.89247221]),\n",
       "  array([0.14950232, 0.97327225, 0.38013402, 0.60019803, 0.10432653,\n",
       "         0.8348806 , 0.85593553, 0.90099403, 0.10343955, 0.77891331]),\n",
       "  array([0.67328004, 0.36135803, 0.95053443, 0.56459606, 0.31688438,\n",
       "         0.11037302, 0.68831867, 0.45309952, 0.16282845, 0.1643249 ,\n",
       "         0.56453003, 0.95589225, 0.74116854, 0.98801356]),\n",
       "  array([0.03532563, 0.88708486, 0.16628265, 0.83382477, 0.36363499,\n",
       "         0.33022915, 0.48118271, 0.04259524, 0.44363114]),\n",
       "  array([0.50302131, 0.4005566 , 0.66117697, 0.04625443, 0.32800646,\n",
       "         0.12777434, 0.47525119]),\n",
       "  array([0.48701663, 0.31746112, 0.54273521, 0.32326027, 0.15245059,\n",
       "         0.0319235 , 0.88856605, 0.55290339, 0.91009639, 0.86818886,\n",
       "         0.99921958, 0.72935641]),\n",
       "  array([0.14797591, 0.36986846, 0.98252529, 0.22556899, 0.82145237,\n",
       "         0.92119657, 0.24270745, 0.27844999, 0.98194636, 0.02393444]),\n",
       "  array([0.223097  , 0.16624819, 0.30502369, 0.41447211, 0.80098468,\n",
       "         0.86136573, 0.62438968, 0.92427032, 0.8382611 , 0.42193487,\n",
       "         0.93379662, 0.12066021, 0.83916133, 0.63824766]),\n",
       "  array([0.63150548, 0.33578777, 0.45221414, 0.15402693, 0.71817033,\n",
       "         0.46252137, 0.1275686 , 0.46421123]),\n",
       "  array([0.87103088, 0.15657182, 0.99957543, 0.34201239, 0.48787306]),\n",
       "  array([0.10782788, 0.19021747, 0.98821753, 0.15815719, 0.5480014 ,\n",
       "         0.33749717, 0.05593222, 0.21077227, 0.78570954]),\n",
       "  array([0.37547698, 0.62376465, 0.02812946, 0.1963343 , 0.78495993,\n",
       "         0.54066081, 0.71296448, 0.64255192, 0.83171413, 0.90861357,\n",
       "         0.6169402 , 0.0540741 , 0.94297405]),\n",
       "  array([0.43253189, 0.48860355, 0.71376496, 0.35734996, 0.33435029,\n",
       "         0.82564749, 0.86376251, 0.91278573, 0.45561902, 0.42836355]),\n",
       "  array([0.4557068 , 0.14168407, 0.81774094, 0.85464095, 0.66056241,\n",
       "         0.68601599]),\n",
       "  array([0.99127666, 0.53978071, 0.98909714, 0.16409429, 0.16413614,\n",
       "         0.81873595, 0.05276318, 0.78791408, 0.39116948, 0.06661826,\n",
       "         0.05531188, 0.5328897 , 0.75934397, 0.1828891 ]),\n",
       "  array([0.1434892 , 0.63373168, 0.31214128, 0.51298286, 0.98337145,\n",
       "         0.61132312, 0.61960264, 0.35744234, 0.41565999, 0.71998955,\n",
       "         0.62833274, 0.26738739, 0.93093126, 0.12015545]),\n",
       "  array([0.06702535, 0.69329871, 0.75588487, 0.61944641, 0.7697723 ]),\n",
       "  array([0.60120597, 0.58515188, 0.15918118, 0.03447896, 0.60172695,\n",
       "         0.25006626, 0.07579376, 0.74130485, 0.54328405, 0.06890871,\n",
       "         0.33528599, 0.44580576, 0.7456062 , 0.77592354]),\n",
       "  array([0.536882  , 0.1526529 , 0.4690006 , 0.58771105, 0.22864285,\n",
       "         0.55480812, 0.93723324, 0.1273441 , 0.81673989, 0.87351058,\n",
       "         0.68864268, 0.33641253, 0.24350682, 0.60703585]),\n",
       "  array([0.52658549, 0.63538027, 0.9019785 , 0.29938133, 0.64904892,\n",
       "         0.47554513, 0.40035806, 0.94292759, 0.6785865 , 0.18953494,\n",
       "         0.66105938, 0.02494921]),\n",
       "  array([0.68844287, 0.09821672, 0.67369954, 0.65218966, 0.13241751,\n",
       "         0.85070306, 0.08045396, 0.27465087, 0.60722052, 0.78331627]),\n",
       "  array([0.23511494, 0.84123044, 0.33445209, 0.67201643, 0.58539251,\n",
       "         0.87946941, 0.13315806, 0.93707046]),\n",
       "  array([0.7473633 , 0.56948126, 0.43410478, 0.27655886, 0.50830432,\n",
       "         0.90979043, 0.57342695, 0.27745388]),\n",
       "  array([0.6180205 , 0.8668595 , 0.98651112, 0.74557628, 0.03753492]),\n",
       "  array([0.53276622, 0.7294263 , 0.82836579, 0.24238545, 0.92577616,\n",
       "         0.23600711, 0.91255908, 0.06295573, 0.81464544, 0.51436122]),\n",
       "  array([0.3221437 , 0.41732738, 0.77098403, 0.39994079, 0.35438695,\n",
       "         0.04956107, 0.45911647, 0.64174246, 0.0532429 , 0.06097392,\n",
       "         0.89463958]),\n",
       "  array([0.86807283, 0.30622479, 0.16367972, 0.43466122, 0.04307696,\n",
       "         0.3441936 , 0.77762499, 0.24740069, 0.83551786, 0.58346256,\n",
       "         0.51374196]),\n",
       "  array([0.74586559, 0.58967334, 0.02348294, 0.33634929, 0.7065717 ,\n",
       "         0.4184539 , 0.92940553, 0.24204229, 0.10152654, 0.62954385]),\n",
       "  array([0.20658302, 0.07195815, 0.26006502, 0.12532333, 0.45898798,\n",
       "         0.0423885 , 0.47623809, 0.89763585, 0.94802853, 0.09178764,\n",
       "         0.42014298, 0.28955683, 0.11481906]),\n",
       "  array([0.00811844, 0.82356859, 0.30540606, 0.1586026 , 0.07663534,\n",
       "         0.45062777, 0.48828582, 0.44928343, 0.04246853, 0.28313478,\n",
       "         0.21380586, 0.00821389, 0.90845645]),\n",
       "  array([0.36818136, 0.92196316, 0.59922365, 0.61457333, 0.23771887,\n",
       "         0.78676048, 0.16804692, 0.56309065, 0.9600963 , 0.72730152]),\n",
       "  array([0.14863931, 0.47524948, 0.25452565, 0.3538481 , 0.30460709,\n",
       "         0.9335852 ]),\n",
       "  array([0.4184211 , 0.85101103, 0.11032419, 0.7104557 , 0.63873746,\n",
       "         0.80267985, 0.79091663]),\n",
       "  array([0.46680088, 0.63502539, 0.10479482, 0.10992063, 0.75385021]),\n",
       "  array([0.08305355, 0.94835183, 0.44669517, 0.28546489, 0.47655126,\n",
       "         0.60891869, 0.98655108]),\n",
       "  array([0.17091205, 0.59350772, 0.81686047, 0.22673781, 0.89706039,\n",
       "         0.84165662, 0.35556536, 0.56341833, 0.99792236, 0.19099736,\n",
       "         0.29855317]),\n",
       "  array([0.5734292 , 0.01963527, 0.43091474, 0.74045691, 0.71045013,\n",
       "         0.7773841 , 0.43348525, 0.85348376, 0.86848762]),\n",
       "  array([0.35254217, 0.06666728, 0.87691777, 0.45623701, 0.6254756 ,\n",
       "         0.92783356]),\n",
       "  array([0.10907993, 0.89847533, 0.8422793 , 0.35448143, 0.53499413,\n",
       "         0.58342064, 0.64281833]),\n",
       "  array([0.37499646, 0.03999111, 0.15238996, 0.00209563, 0.22869913,\n",
       "         0.36197068]),\n",
       "  array([0.52650249, 0.09493967, 0.08320876, 0.39920773, 0.8324024 ,\n",
       "         0.60908641, 0.40985007, 0.7780799 , 0.95242196, 0.46203569,\n",
       "         0.91111071]),\n",
       "  array([0.12772575, 0.61658156, 0.71581205, 0.93140941, 0.88869118,\n",
       "         0.10407406, 0.41259306, 0.8464024 , 0.64035807, 0.80542543]),\n",
       "  array([0.53842375, 0.35738371, 0.90065142, 0.56194563, 0.36491949,\n",
       "         0.89490023, 0.44286987, 0.83980656, 0.08029093, 0.25893475,\n",
       "         0.01830846]),\n",
       "  array([0.75653299, 0.02536744, 0.56420863, 0.34190963, 0.4886017 ,\n",
       "         0.1025151 , 0.33110439, 0.35955558]),\n",
       "  array([0.16913965, 0.26865361, 0.73504056, 0.83823793, 0.06960749,\n",
       "         0.36115937, 0.16999864, 0.0450811 , 0.19983836, 0.52124738,\n",
       "         0.92915717]),\n",
       "  array([0.15877835, 0.53331663, 0.38884828, 0.86352264, 0.82784228,\n",
       "         0.75617924, 0.85563301, 0.07021149, 0.69039912, 0.53451402]),\n",
       "  array([0.51161402, 0.39326772, 0.8489085 , 0.74622199, 0.71850092,\n",
       "         0.91075393]),\n",
       "  array([0.44710646, 0.70770012, 0.51799348, 0.50534681, 0.72102632,\n",
       "         0.29372495, 0.11089003, 0.99915389, 0.19756034, 0.99588801,\n",
       "         0.12158343]),\n",
       "  array([0.51935203, 0.18921399, 0.82396019, 0.18705328, 0.03464948,\n",
       "         0.10218365, 0.96273127, 0.01907182, 0.69765045, 0.61847166,\n",
       "         0.71369525, 0.35075074, 0.99266789, 0.99916138]),\n",
       "  array([0.95071944, 0.21314528, 0.94079928, 0.88912531, 0.5438917 ,\n",
       "         0.77451443]),\n",
       "  array([0.5697073 , 0.95392567, 0.74050968, 0.63775371, 0.06966255,\n",
       "         0.33995839, 0.75310466]),\n",
       "  array([0.13659934, 0.39347833, 0.94211655, 0.89315639, 0.35664705,\n",
       "         0.2351653 , 0.90544516, 0.98333272, 0.75563752, 0.39148305,\n",
       "         0.09809402, 0.12552877, 0.09169278]),\n",
       "  array([0.21300454, 0.30644538, 0.64342266, 0.58907066, 0.60522749,\n",
       "         0.85070008, 0.90983608, 0.70797923, 0.09459071, 0.1976256 ,\n",
       "         0.10659881, 0.70392254, 0.71343335]),\n",
       "  array([0.54104641, 0.75499588, 0.64731208, 0.01252613, 0.22661653,\n",
       "         0.81702783, 0.65456554, 0.54486202, 0.85710419, 0.9908342 ,\n",
       "         0.60704293]),\n",
       "  array([0.67982636, 0.80131397, 0.39891884, 0.19521455, 0.53889005,\n",
       "         0.65519361, 0.9247569 , 0.86779574, 0.88054365]),\n",
       "  array([0.7444562 , 0.5832442 , 0.73435896, 0.85297317, 0.90179369,\n",
       "         0.0926009 ]),\n",
       "  array([0.76133451, 0.28498712, 0.69028679, 0.06615536, 0.06324819,\n",
       "         0.9839244 , 0.68818537])],\n",
       " [array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       "  array([0, 0, 1, 1, 1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 1])],\n",
       " [8,\n",
       "  13,\n",
       "  6,\n",
       "  13,\n",
       "  11,\n",
       "  8,\n",
       "  12,\n",
       "  11,\n",
       "  7,\n",
       "  14,\n",
       "  8,\n",
       "  6,\n",
       "  12,\n",
       "  8,\n",
       "  6,\n",
       "  11,\n",
       "  13,\n",
       "  11,\n",
       "  6,\n",
       "  8,\n",
       "  12,\n",
       "  6,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  14,\n",
       "  14,\n",
       "  11,\n",
       "  13,\n",
       "  11,\n",
       "  10,\n",
       "  5,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  13,\n",
       "  7,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  14,\n",
       "  6,\n",
       "  10,\n",
       "  14,\n",
       "  10,\n",
       "  14,\n",
       "  9,\n",
       "  7,\n",
       "  12,\n",
       "  10,\n",
       "  14,\n",
       "  8,\n",
       "  5,\n",
       "  9,\n",
       "  13,\n",
       "  10,\n",
       "  6,\n",
       "  14,\n",
       "  14,\n",
       "  5,\n",
       "  14,\n",
       "  14,\n",
       "  12,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  5,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  13,\n",
       "  13,\n",
       "  10,\n",
       "  6,\n",
       "  7,\n",
       "  5,\n",
       "  7,\n",
       "  11,\n",
       "  9,\n",
       "  6,\n",
       "  7,\n",
       "  6,\n",
       "  11,\n",
       "  10,\n",
       "  11,\n",
       "  8,\n",
       "  11,\n",
       "  10,\n",
       "  6,\n",
       "  11,\n",
       "  14,\n",
       "  6,\n",
       "  7,\n",
       "  13,\n",
       "  13,\n",
       "  11,\n",
       "  9,\n",
       "  6,\n",
       "  7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate train and test data.\n",
    "x_train, y_train, sequence_length_train = get_examples(100)\n",
    "x_test, y_test, sequence_length_test = get_examples(30)\n",
    "\n",
    "x_train, y_train, sequence_length_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-20b9cd4de139>:17: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-10-20b9cd4de139>:25: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/Sun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/Sun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/Sun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional LSTM + CRF model.\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "input_size = 1\n",
    "batch_size = 32\n",
    "num_units = 128 # the number of units in the LSTM cell\n",
    "number_of_classes = 2\n",
    "\n",
    "input_data = tf.placeholder(tf.float32, [None, None, input_size], name=\"input_data\") # shape = (batch, batch_seq_len, input_size)\n",
    "labels = tf.placeholder(tf.int32, shape=[None, None], name=\"labels\") # shape = (batch, sentence)\n",
    "batch_sequence_length = tf.placeholder(tf.int32) # max sequence length in batch\n",
    "original_sequence_lengths = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Scope is mandatory to use LSTMCell (https://github.com/tensorflow/tensorflow/issues/799).\n",
    "with tf.name_scope(\"BiLSTM\"):\n",
    "    with tf.variable_scope('forward'):\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n",
    "    with tf.variable_scope('backward'):\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n",
    "    (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_fw_cell, \n",
    "                                                                     cell_bw=lstm_bw_cell, \n",
    "                                                                     inputs=input_data,\n",
    "                                                                     sequence_length=original_sequence_lengths, \n",
    "                                                                     dtype=tf.float32,\n",
    "                                                                     scope=\"BiLSTM\")\n",
    "\n",
    "# As we have a Bi-LSTM, we have two outputs which are not connected, so we need to merge them.\n",
    "outputs = tf.concat([output_fw, output_bw], axis=2)\n",
    "\n",
    "# Fully connected layer.\n",
    "W = tf.get_variable(name=\"W\", shape=[2 * num_units, number_of_classes],\n",
    "                dtype=tf.float32)\n",
    "\n",
    "b = tf.get_variable(name=\"b\", shape=[number_of_classes], dtype=tf.float32,\n",
    "                initializer=tf.zeros_initializer())\n",
    "\n",
    "outputs_flat = tf.reshape(outputs, [-1, 2 * num_units])\n",
    "pred = tf.matmul(outputs_flat, W) + b\n",
    "scores = tf.reshape(pred, [-1, batch_sequence_length, number_of_classes])\n",
    "\n",
    "# Linear-CRF.\n",
    "log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(scores, labels, original_sequence_lengths)\n",
    "\n",
    "loss = tf.reduce_mean(-log_likelihood)\n",
    "\n",
    "# Compute the viterbi sequence and score (used for prediction and test time).\n",
    "viterbi_sequence, viterbi_score = tf.contrib.crf.crf_decode(scores, transition_params, original_sequence_lengths)\n",
    "\n",
    "# Training ops.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 44.27%\n",
      "Epoch: 0 Accuracy: 43.64%\n",
      "Epoch: 0 Accuracy: 41.16%\n",
      "Epoch: 0 Accuracy: 45.45%\n",
      "Epoch: 10 Accuracy: 91.08%\n",
      "Epoch: 10 Accuracy: 93.33%\n",
      "Epoch: 10 Accuracy: 89.80%\n",
      "Epoch: 10 Accuracy: 100.00%\n",
      "Epoch: 20 Accuracy: 92.99%\n",
      "Epoch: 20 Accuracy: 93.64%\n",
      "Epoch: 20 Accuracy: 91.16%\n",
      "Epoch: 20 Accuracy: 100.00%\n",
      "Epoch: 30 Accuracy: 92.68%\n",
      "Epoch: 30 Accuracy: 93.64%\n",
      "Epoch: 30 Accuracy: 91.84%\n",
      "Epoch: 30 Accuracy: 100.00%\n",
      "Epoch: 40 Accuracy: 94.27%\n",
      "Epoch: 40 Accuracy: 94.85%\n",
      "Epoch: 40 Accuracy: 93.88%\n",
      "Epoch: 40 Accuracy: 100.00%\n",
      "Epoch: 50 Accuracy: 94.59%\n",
      "Epoch: 50 Accuracy: 96.36%\n",
      "Epoch: 50 Accuracy: 93.54%\n",
      "Epoch: 50 Accuracy: 100.00%\n",
      "Epoch: 60 Accuracy: 95.22%\n",
      "Epoch: 60 Accuracy: 96.36%\n",
      "Epoch: 60 Accuracy: 93.88%\n",
      "Epoch: 60 Accuracy: 100.00%\n",
      "Epoch: 70 Accuracy: 96.18%\n",
      "Epoch: 70 Accuracy: 96.06%\n",
      "Epoch: 70 Accuracy: 95.24%\n",
      "Epoch: 70 Accuracy: 100.00%\n",
      "Epoch: 80 Accuracy: 97.13%\n",
      "Epoch: 80 Accuracy: 94.85%\n",
      "Epoch: 80 Accuracy: 95.58%\n",
      "Epoch: 80 Accuracy: 100.00%\n",
      "Epoch: 90 Accuracy: 96.82%\n",
      "Epoch: 90 Accuracy: 97.27%\n",
      "Epoch: 90 Accuracy: 96.26%\n",
      "Epoch: 90 Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Training the model.\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(training_epochs):\n",
    "        for batch_data, batch_labels, batch_seq_len, batch_sequence_lengths in batch(x_train, y_train, sequence_length_train, batch_size, input_size):\n",
    "            tf_viterbi_sequence, _ = session.run([viterbi_sequence, train_op], \n",
    "                                                 feed_dict={input_data: batch_data, \n",
    "                                                            labels: batch_labels, \n",
    "                                                            batch_sequence_length: batch_seq_len,\n",
    "                                                            original_sequence_lengths: batch_sequence_lengths })\n",
    "            # Show train accuracy.\n",
    "            if i % 10 == 0:\n",
    "                # Create a mask to fix input lengths.\n",
    "                mask = (np.expand_dims(np.arange(batch_seq_len), axis=0) <\n",
    "                    np.expand_dims(batch_sequence_lengths, axis=1))\n",
    "                total_labels = np.sum(batch_sequence_lengths)\n",
    "                correct_labels = np.sum((batch_labels == tf_viterbi_sequence) * mask)\n",
    "                accuracy = 100.0 * correct_labels / float(total_labels)\n",
    "                print(\"Epoch: %d\" % i, \"Accuracy: %.2f%%\" % accuracy)\n",
    "    \n",
    "    # Save the variables to disk.\n",
    "    saver.save(session, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "Test accuracy: 95.97%\n",
      "Label: [0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "Pred.: [0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model.\n",
    "with tf.Session() as session:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(session, MODEL_PATH)\n",
    "    \n",
    "    for batch_data, batch_labels, batch_seq_len, batch_sequence_lengths in batch(x_test, y_test, sequence_length_test, len(x_test), input_size):\n",
    "        tf_viterbi_sequence = session.run(viterbi_sequence, feed_dict={input_data: batch_data, \n",
    "                                                                       labels: batch_labels, \n",
    "                                                                       batch_sequence_length: batch_seq_len,\n",
    "                                                                       original_sequence_lengths: batch_sequence_lengths })\n",
    "    # mask to correct input sizes\n",
    "    mask = (np.expand_dims(np.arange(batch_seq_len), axis=0) <\n",
    "        np.expand_dims(batch_sequence_lengths, axis=1))\n",
    "    total_labels = np.sum(batch_sequence_lengths)\n",
    "    correct_labels = np.sum((batch_labels == tf_viterbi_sequence) * mask)\n",
    "    accuracy = 100.0 * correct_labels / float(total_labels)\n",
    "    print(\"Test accuracy: %.2f%%\" % accuracy)\n",
    "\n",
    "    print(\"Label:\", batch_labels[0].astype(int))    \n",
    "    print(\"Pred.:\", tf_viterbi_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
